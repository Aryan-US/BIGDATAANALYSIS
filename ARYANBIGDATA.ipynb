{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIZ02lGsPaRV"
      },
      "outputs": [],
      "source": [
        "!pip install pyarrow -q\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "import requests\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"EcommerceBigDataAnalysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "data_url = \"https://raw.githubusercontent.com/databricks/Spark-The-Definitive-Guide/master/data/retail-data/all/online-retail-dataset.csv\"\n",
        "local_file_path = \"/content/ecommerce_data.csv\"\n",
        "\n",
        "print(\"Downloading E-commerce dataset...\")\n",
        "response = requests.get(data_url, stream=True)\n",
        "response.raise_for_status()\n",
        "\n",
        "with open(local_file_path, 'wb') as f:\n",
        "    for chunk in response.iter_content(chunk_size=1024*1024):\n",
        "        f.write(chunk)\n",
        "print(f\"Download complete! File saved at: {local_file_path}\")\n",
        "\n",
        "\n",
        "\n",
        "df = spark.read.csv(local_file_path, header=True, inferSchema=True)\n",
        "df_clean = df.filter((F.col(\"Quantity\") > 0) & (F.col(\"UnitPrice\") > 0))\n",
        "\n",
        "\n",
        "# Calculate Total Sales per transaction: Quantity * UnitPrice\n",
        "df_with_revenue = df_clean.withColumn(\"TotalRevenue\", F.col(\"Quantity\") * F.col(\"UnitPrice\"))\n",
        "\n",
        "print(f\"\\n--- SUCCESS: DATA LOADED ---\")\n",
        "print(f\"Total rows analyzed: {df_clean.count():,}\")\n",
        "\n",
        "# Insight 1: Top 10 Countries by Revenue\n",
        "print(\"\\n--- GLOBAL REVENUE BY COUNTRY ---\")\n",
        "revenue_insights = df_with_revenue.groupBy(\"Country\") \\\n",
        "    .agg(\n",
        "        F.sum(\"TotalRevenue\").alias(\"Total_Sales\"),\n",
        "        F.count(\"InvoiceNo\").alias(\"Transaction_Volume\"),\n",
        "        F.avg(\"TotalRevenue\").alias(\"Avg_Order_Value\")\n",
        "    ) \\\n",
        "    .orderBy(F.desc(\"Total_Sales\"))\n",
        "\n",
        "revenue_insights.show(10)\n",
        "\n",
        "# Insight 2: Peak Shopping Hours (Time-Series Analysis)\n",
        "\n",
        "print(\"\\n--- BUSIEST SHOPPING HOURS (24h Format) ---\")\n",
        "hourly_sales = df_clean.withColumn(\"Hour\", F.hour(F.to_timestamp(F.col(\"InvoiceDate\"), \"M/d/yyyy H:mm\"))) \\\n",
        "    .groupBy(\"Hour\") \\\n",
        "    .count() \\\n",
        "    .orderBy(\"Hour\")\n",
        "\n",
        "hourly_sales.show(24)\n",
        "\n",
        "# 10. End Session\n",
        "# spark.stop()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifying top 10 customers by total spend\n",
        "print(\"\\n--- TOP 10 CUSTOMERS BY SPEND ---\")\n",
        "top_customers = df_with_revenue.groupBy(\"CustomerID\") \\\n",
        "    .agg(\n",
        "        F.sum(\"TotalRevenue\").alias(\"Total_Spent\"),\n",
        "        F.count(\"InvoiceNo\").alias(\"Total_Orders\")\n",
        "    ) \\\n",
        "    .filter(F.col(\"CustomerID\").isNotNull()) \\\n",
        "    .orderBy(F.desc(\"Total_Spent\"))\n",
        "\n",
        "top_customers.show(10)"
      ],
      "metadata": {
        "id": "hdAeqDKJbMYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 Products by Total Revenue\n",
        "print(\"\\n--- TOP 10 PRODUCTS BY REVENUE ---\")\n",
        "product_performance = df_with_revenue.groupBy(\"Description\") \\\n",
        "    .agg(\n",
        "        F.sum(\"TotalRevenue\").alias(\"Product_Revenue\"),\n",
        "        F.sum(\"Quantity\").alias(\"Units_Sold\")\n",
        "    ) \\\n",
        "    .orderBy(F.desc(\"Product_Revenue\"))\n",
        "\n",
        "product_performance.show(10, truncate=False)"
      ],
      "metadata": {
        "id": "iAxko37pbWGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Most popular products in specific countries\n",
        "print(\"\\n--- TOP PRODUCTS PER COUNTRY (Volume) ---\")\n",
        "regional_trends = df_with_revenue.groupBy(\"Country\", \"Description\") \\\n",
        "    .agg(F.sum(\"Quantity\").alias(\"Total_Quantity\")) \\\n",
        "    .orderBy(F.desc(\"Total_Quantity\"))\n",
        "\n",
        "# Showing top 15 results across all regions\n",
        "regional_trends.show(15, truncate=False)"
      ],
      "metadata": {
        "id": "hqtwD2-PbeFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 = Sunday, 2 = Monday, ..., 7 = Saturday\n",
        "print(\"\\n--- SALES VOLUME BY DAY OF WEEK ---\")\n",
        "day_of_week_analysis = df_with_revenue.withColumn(\"DayOfWeek\", F.dayofweek(F.to_timestamp(F.col(\"InvoiceDate\"), \"M/d/yyyy H:mm\"))) \\\n",
        "    .groupBy(\"DayOfWeek\") \\\n",
        "    .count() \\\n",
        "    .orderBy(\"DayOfWeek\")\n",
        "\n",
        "day_of_week_analysis.show()"
      ],
      "metadata": {
        "id": "H-UX0lXoblAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reloading data specifically to look at cancellations/returns\n",
        "df_returns = df.filter(F.col(\"Quantity\") < 0)\n",
        "\n",
        "print(f\"\\n--- DATA QUALITY INSIGHT ---\")\n",
        "print(f\"Total number of cancellations/returns: {df_returns.count():,}\")\n",
        "\n",
        "# Top countries with the most returns\n",
        "df_returns.groupBy(\"Country\").count().orderBy(F.desc(\"count\")).show(5)"
      ],
      "metadata": {
        "id": "qcXSU5Tmbzxz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}